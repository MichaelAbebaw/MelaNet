{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "Model is inspired by Baidu 2.\n",
    "See models/model_2.png for architecture diagram. Save model on every epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train and valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generator import make_audio_gen\n",
    "\n",
    "\n",
    "TRAIN_CORPUS = \"data_stbbl/train_corpus.json\"\n",
    "VALID_CORPUS = \"data_stbbl/valid_corpus.json\"\n",
    "\n",
    "MFCC_DIM = 13\n",
    "SPECTOGRAM = False\n",
    "EPOCHS = 2\n",
    "MODEL_NAME = \"model_2_stbbl\"\n",
    "\n",
    "################ Reminder MINI_BATCH_SIZE=250 in previous notebooks\n",
    "MINI_BATCH_SIZE = 50\n",
    "\n",
    "SORT_BY_DURATION=False\n",
    "MAX_DURATION = 10.0\n",
    "\n",
    "audio_gen = make_audio_gen(TRAIN_CORPUS, VALID_CORPUS, spectrogram=False, mfcc_dim=MFCC_DIM,\n",
    "                           minibatch_size=MINI_BATCH_SIZE, sort_by_duration=SORT_BY_DURATION,\n",
    "                           max_duration=MAX_DURATION)\n",
    "# add the training data to the generator\n",
    "audio_gen.load_train_data()\n",
    "audio_gen.load_validation_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       (None, None, 13)          0         \n",
      "_________________________________________________________________\n",
      "layer_1_conv (Conv1D)        (None, None, 200)         28800     \n",
      "_________________________________________________________________\n",
      "conv_batch_norm (BatchNormal (None, None, 200)         800       \n",
      "_________________________________________________________________\n",
      "rnn_1 (GRU)                  (None, None, 250)         338250    \n",
      "_________________________________________________________________\n",
      "bt_rnn_1 (BatchNormalization (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "rnn_2 (GRU)                  (None, None, 250)         375750    \n",
      "_________________________________________________________________\n",
      "bt_rnn_2 (BatchNormalization (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "rnn_3 (GRU)                  (None, None, 250)         375750    \n",
      "_________________________________________________________________\n",
      "bt_rnn_3 (BatchNormalization (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "rnn_4 (GRU)                  (None, None, 250)         375750    \n",
      "_________________________________________________________________\n",
      "bt_rnn_4 (BatchNormalization (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "final_layer_of_rnn (GRU)     (None, None, 250)         375750    \n",
      "_________________________________________________________________\n",
      "bt_rnn_final (BatchNormaliza (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 223)         55973     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 223)         0         \n",
      "=================================================================\n",
      "Total params: 1,931,823\n",
      "Trainable params: 1,928,923\n",
      "Non-trainable params: 2,900\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/40\n",
      " 52/125 [===========>..................] - ETA: 29:29 - loss: 202.9150"
     ]
    }
   ],
   "source": [
    "from src.train import train\n",
    "from src.models import model_2\n",
    "from src.char_map import char_map, index_map\n",
    "\n",
    "EPOCHS = 40\n",
    "MODEL_NAME = \"model_2_stbbl\"\n",
    "\n",
    "model = model_2(input_dim=13,\n",
    "                filters=200,\n",
    "                kernel_size=11, \n",
    "                conv_stride=2,\n",
    "                conv_border_mode='valid',\n",
    "                units=250,\n",
    "                activation='relu',\n",
    "                dropout_rate=1,\n",
    "                number_of_layers=5,\n",
    "                output_dim=len(char_map)+1)\n",
    "\n",
    "train(audio_gen, input_to_softmax=model, model_name=MODEL_NAME, epochs=EPOCHS, minibatch_size=MINI_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.char_map import char_map, index_map\n",
    "from src.models import model_2\n",
    "\n",
    "model = model_2(input_dim=13,\n",
    "                filters=200,\n",
    "                kernel_size=11, \n",
    "                conv_stride=2,\n",
    "                conv_border_mode='valid',\n",
    "                units=250,\n",
    "                activation='relu',\n",
    "                dropout_rate=1,\n",
    "                number_of_layers=5,\n",
    "                output_dim=len(char_map)+1)\n",
    "model_name = \"model_2_stbbl\"\n",
    "model.load_weights('models/' + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot import plot_hist\n",
    "\n",
    "model_name = \"model_2_stbbl\"\n",
    "plot_hist(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Error Rate - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.predict import calculate_wer\n",
    "\n",
    "calculate_wer(model, model_name, audio_gen, 'train', audio_gen.train_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.predict import load_wer\n",
    "\n",
    "wer = load_wer(model_name, 'train')\n",
    "print(\"WER mean=%f std=%f\" % (np.std(wer), np.mean(wer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Error Rate - validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.predict import calculate_wer\n",
    "from src.data_generator import VALID_LENGTH\n",
    "\n",
    "calculate_wer(model, model_name, 'validation', VALID_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.predict import load_wer\n",
    "\n",
    "wer = load_wer(model_name, 'validation')\n",
    "print(\"WER mean=%f std=%f\" % (np.std(wer), np.mean(wer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample prediction - training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from src.predict import predict\n",
    "\n",
    "predict(0, 'train', model)\n",
    "predict(1, 'train', model)\n",
    "predict(2, 'train', model)\n",
    "predict(3, 'train', model)\n",
    "predict(4, 'train', model)\n",
    "predict(5, 'train', model)\n",
    "predict(6, 'train', model)\n",
    "predict(7, 'train', model)\n",
    "predict(8, 'train', model)\n",
    "predict(9, 'train', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample prediction - validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from src.predict import predict\n",
    "\n",
    "wer = pickle.load(open('models/' + model_name + '_validation_wer.pickle', \"rb\" ))\n",
    "wer_index = np.argsort(wer)\n",
    "predict(wer_index[0], 'validation', model)\n",
    "predict(wer_index[1], 'validation', model)\n",
    "predict(wer_index[2], 'validation', model)\n",
    "predict(wer_index[3], 'validation', model)\n",
    "predict(wer_index[4], 'validation', model)\n",
    "predict(wer_index[5], 'validation', model)\n",
    "predict(wer_index[-1], 'validation', model)\n",
    "predict(wer_index[-2], 'validation', model)\n",
    "predict(wer_index[-3], 'validation', model)\n",
    "predict(wer_index[-4], 'validation', model)\n",
    "predict(wer_index[-5], 'validation', model)\n",
    "predict(wer_index[-6], 'validation', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
